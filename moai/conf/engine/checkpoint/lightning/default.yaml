# @package trainer.checkpoint

_target_: pytorch_lightning.callbacks.ModelCheckpoint
monitor: ??? # metric to monitor
verbose: false
save_weights_only: false
mode: min # (PTL 1.5 removed auto) max or min depending on where the metric is an accuracy or error above (with auto it is determined by 'acc' or 'loss')
#NOTE: @PTRL1.5 period: 1 # number of epochs between checkpoints
#NOTE: @PTRL1.5 prefix: ${experiment.name}
save_top_k: 3
save_last: true                                
dirpath: null
filename: ??? # '{epoch}-{val_loss:.2f}-{other_metric:.2f}'
auto_insert_metric_name: true
every_n_train_steps: null
train_time_interval: null
every_n_epochs: 1
save_on_train_epoch_end: false