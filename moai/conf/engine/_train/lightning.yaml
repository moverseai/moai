# @package trainer

_target_: moai.engine.lightning.train.LightningTrainer
################
# train options
################
max_epochs: 30
min_epochs: 1
check_val_every_n_epoch: 1
gradient_clip_val: 0 # 0 means don't clip.
gradient_clip_algorithm: norm # one of [value, norm]
accumulate_grad_batches: 1
overfit_batches: 0.0
limit_train_batches: 1.0
limit_val_batches: 1.0
limit_test_batches: 1.0
limit_predict_batches: 1.0
val_check_interval: 1.0
#NOTE: @PTL1.5 deprecated reload_dataloaders_every_epoch: false # Set to True to reload dataloaders every epoch
reload_dataloaders_every_n_epochs: 0 # et to a positive integer to reload dataloaders every n epochs.
deterministic: true
# auto_lr_find: false
# terminate_on_nan: false # removed in PTL2.1
# auto_scale_batch_size: false # removed in PTL2.1
#NOTE: @PTL1.5 automatic_optimization: true

################
# backend options
################
num_nodes: 1 # only for the distributed case / number of GPU nodes for distributed training.
# num_processes: 1
### ___gpus___ MUST BE STRING TO OVERCOME HYDRA/LIGHTNING TYPE ISSUES
### NOTE: see https://pytorch-lightning.readthedocs.io/en/stable/multi_gpu.html#select-gpu-devices 
accelerator: auto
strategy: auto #NOTE: https://lightning.ai/docs/pytorch/stable/extensions/strategy.html
devices: auto
gpus: auto # TODO: remove this in PTL2.1 and use devices instead
precision: 32 # Full precision (32), half precision (16).
benchmark: false # if true enables cudnn benchmark
# prepare_data_per_node: true # rmoved in PTL2.1
replace_sampler_ddp: true
plugins: null
#distributed_backend: null
enable_model_summary: true #NOTE: @PTL1.5
detect_anomaly: false #NOTE: @PTL1.5
################
### log options
################
flush_logs_every_n_steps: 100
log_every_n_steps: 10
# progress_bar_refresh_rate: 1 # How often to refresh progress bar (in steps). Value ``0`` disables progress bar. - NOTE: deprecated show_progress_bar: true # uses tqdm in cli
# log_gpu_memory: all # requires nvidia-smi in path - NOTE: None, 'min_max', 'all'.  
# weights_summary: top # or full / null # removed in PTL2.1
profiler: simple # comment out for passthrough profiler, cannot use advanced one yet
default_root_dir: ''

################
### debug options
################
fast_dev_run: false
num_sanity_val_steps: 2
# track_grad_norm: -1 #-1 is do not track - NOTE: removed in PTL2.1

################
### other options
################
# process_position: 0 # orders the tqdm bar when running multiple models on same machine.
# move_metrics_to_cpu: false # removed in PTL2.1
# multiple_trainloader_mode: max_size_cycle # removed in PTL2.1
# stochastic_weight_avg: false # removed in PTL2.1